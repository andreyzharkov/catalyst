common_hyperparams:
  noise_dim: &noise_dim 16
  # ensure the names below are the same as in your runner ("discriminator_train" & "generator_train")
  discriminator_train_phase: &discriminator_train_phase critic_train
  generator_train_phase: &generator_train_phase generator_train

model_params:
  _key_value: True
  generator:
    model: SimpleGenerator
    noise_dim: *noise_dim
  critic:
    model: SimpleDiscriminator


args:
  expdir: "mnist_advanced_gans"
  baselogdir: "./logs/mnist_advanced_gans/vanilla_wgan_gp"


stages:

  data_params:
    batch_size: 64
    num_workers: 0

  state_params:
    num_epochs: 100
    main_metric: &reduce_metric loss_g
    minimize_metric: True
    batch_consistant_metrics: False

  criterion_params:
    _key_value: True
    mean_output_loss:
      criterion: MeanOutputLoss
    gradient_penalty:
      criterion: GradientPenaltyLoss

  callbacks_params:
    phase_manager:
      callback: PhaseManagerCallback
      # one of "all" (use all callbacks), "same" (same phases as in train)
      valid_mode: "all"
      train_phases:
        *discriminator_train_phase: 5
        *generator_train_phase: 1

    prepare_batch_noise:
      callback: AddBatchNoiseCallback
      noise_shape: *noise_dim

    loss_g:
      _wrapper: &g_train_wrapper
        callback: PhaseBatchWrapperCallback
        active_phases: [*generator_train_phase]
      callback: CriterionCallback
      input_key:  # input key does not matter
      output_key: "fake_validity"
      criterion_key: mean_output_loss
      prefix: loss_g
      multiplier: -1.0

    loss_d_real:
      _wrapper: &d_train_wrapper
        callback: PhaseBatchWrapperCallback
        active_phases: [*discriminator_train_phase]
      callback: CriterionCallback
      input_key:  # input key does not matter
      output_key: "real_validity"
      criterion_key: mean_output_loss
      prefix: loss_d_real
    loss_d_fake:
      _wrapper: *d_train_wrapper
      callback: CriterionCallback
      input_key:  # input key does not matter
      output_key: "fake_validity"
      criterion_key: mean_output_loss
      prefix: loss_d_fake
    loss_d_gp:
      _wrapper: *d_train_wrapper
      callback: CriterionWithDiscriminatorCallback
      input_key: "data"
      output_key: "fake_data"
      criterion_key: gradient_penalty
      discriminator_model_key: critic
      prefix: "loss_d_gp"
    loss_d:
      _wrapper: *d_train_wrapper
      callback: WeightedCriterionAggregatorCallback
      loss_aggregate_fn: "sum"
      prefix: &loss_d loss_d
      loss_keys:
        - loss_d_real
        - loss_d_fake
        - loss_d_gp
      weights:
        - -1.0
        - 1.0
        - 10.0  # gradient penalty multiplier

    optim_g:
      _wrapper: *g_train_wrapper
      callback: OptimizerCallback
      optimizer_key: generator
      loss_key: loss_g
    optim_d:
      _wrapper: *d_train_wrapper
      callback: OptimizerCallback
      optimizer_key: discriminator
      loss_key: loss_d

    wasserstein_distance:
      _wrapper: *d_train_wrapper
      callback: WassersteinDistanceCallback
      prefix: "wasserstein_distance"
      real_validity_output_key: "real_validity"
      fake_validity_output_key: "fake_validity"

    visualizer:
      callback: VisualizationCallback
      output_keys: "fake_data"
      n_row: 5
      max_images: 25

    saver:
      callback: CheckpointCallback

  stage1:

    optimizer_params:
      _key_value: True
      generator:
        optimizer: Adam
        _model: ["generator"]
        lr: 0.0001
        betas:
          - 0.5
          - 0.9
      discriminator:
        optimizer: Adam
        _model: ["critic"]
        lr: 0.0001
        betas:
          - 0.5
          - 0.9
